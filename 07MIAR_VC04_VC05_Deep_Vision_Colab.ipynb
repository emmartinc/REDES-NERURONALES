{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oTlHf22PigwY",
        "-xgqejLMinyM",
        "0yhEXcdHi4Aj",
        "DlyJFsn_jHfj",
        "-zbIKienjdhb",
        "9QfK8aj0klct",
        "kSb1uTpJn_eC",
        "TSXhGQa3PQKc",
        "bEgHlw7oPSl6",
        "3jiAe2cEPk0Y",
        "9bKNJiApNHlj",
        "Yk8Q9thGve4T",
        "BjwW0XUHNHnM"
      ]
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_xGbf7WNHiE"
      },
      "source": [
        "# 07MAIR - Redes Neuronales y Deep Learning\n",
        "## VC04_V05: Deep Learning y Deep vision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRoU6uh8NM1W"
      },
      "source": [
        "# SOLO PARA USO EN GOOGLE COLABORATORY\n",
        "# Para conectar el notebook con la cuenta de gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "BASE_FOLDER = '/content/drive/My Drive/VIU/07_RN_MIAR/03.Materiales_del_profesor/' # Se debe garantizar que la carpeta docencia compartida se almacena en el directorio raíz de Google Drive. En caso contrario modificar este path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciones base\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_learning_curve(H):\n",
        "  epochs = H.history[\"loss\"]\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure()\n",
        "  plt.plot(np.arange(0, epochs), H.history[\"loss\"], label=\"train_loss\")\n",
        "  plt.plot(np.arange(0, epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "  plt.plot(np.arange(0, epochs), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "  plt.plot(np.arange(0, epochs), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "  plt.title(\"Training Loss and Accuracy\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss/Accuracy\")\n",
        "  plt.legend()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def evaluate_model(model, x, y):\n",
        "  print(\"[INFO]: Evaluando red neuronal...\")\n",
        "  predictions = convnet.predict(x_te, batch_size=128)\n",
        "  print(classification_report(y_test, predictions.argmax(axis=1)))"
      ],
      "metadata": {
        "id": "QaIY2iQC3P4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTlHf22PigwY"
      },
      "source": [
        "## **INTRODUCCIÓN A LAS CONVOLUTIONAL NEURAL NETWORKS: MNIST DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHzrsKHQDMmQ"
      },
      "source": [
        "#### **- Cargando el conjunto de datos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGzZ11xaNHip"
      },
      "source": [
        "# Cargar dataset de mnist\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJr2bhE4DZYk"
      },
      "source": [
        "#### **- Acondicionando el conjunto de datos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peYCCxEbDZ44"
      },
      "source": [
        "# Pre-procesado obligatorio cuando trabajo con redes neuronales\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.backend import expand_dims\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMztv3a5Kqou"
      },
      "source": [
        "#### **- Creando la topología de Red Neuronal (CNN) y entrenándola**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp3kAblVNHi0"
      },
      "source": [
        "# Construccion de una red CNN\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Red feedforward API secuencial\n",
        "convnet = Sequential()\n",
        "\n",
        "# BASE MODEL\n",
        "\n",
        "# TOP MODEL\n",
        "\n",
        "convnet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEZ4HAfGNHjB"
      },
      "source": [
        "# Compilación\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myf0nixeNHjH"
      },
      "source": [
        "# Entrenamiento"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj3IHdxIKzpe"
      },
      "source": [
        "#### **- Observando el proceso de entrenamiento para tomar decisiones**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4umol-sJ7zw"
      },
      "source": [
        "# Evaluación + Testeo\n",
        "\n",
        "# Learning curves\n",
        "visualize_learning_curve(...)\n",
        "\n",
        "# Evaluando el modelo de predicción con las imágenes de test\n",
        "evaluate_model(...)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xgqejLMinyM"
      },
      "source": [
        "## **¿POR QUE CONVOLUTIONAL NEURAL NETWORKS?: CIFAR DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yhEXcdHi4Aj"
      },
      "source": [
        "#### **- Cargando el conjunto de datos y acondicionándolo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNcO0aXZiygR"
      },
      "source": [
        "# Importando el set de datos CIFAR10\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlyJFsn_jHfj"
      },
      "source": [
        "#### **- Inspeccionando el conjunto de datos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QQPADCujG_x"
      },
      "source": [
        "# Inspección del conjunto de datos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zbIKienjdhb"
      },
      "source": [
        "#### **- Creando la topología de red neuronal y entrenándola: MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW5UawlPj3zy"
      },
      "source": [
        "# Arquitectura de red - modo API Sequential\n",
        "\n",
        "# Compilamos el modelo y entrenamos\n",
        "\n",
        "# Entrenamos el perceptrón multicapa\n",
        "\n",
        "# Learning curves\n",
        "visualize_learning_curve(...)\n",
        "\n",
        "# Evaluando el modelo de predicción con las imágenes de test\n",
        "evaluate_model(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QfK8aj0klct"
      },
      "source": [
        "#### **- Creando la topología de red neuronal y entrenándola: CNN**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Arquitectura de red - modo API Functional\n",
        "\n",
        "# 1.BASE MODEL\n",
        "\n",
        "# 2.TOP MODEL\n",
        "\n",
        "# 3. Unimos las entradas y salidas del modelo\n",
        "\n",
        "# Compilamos el modelo y entrenamos\n",
        "\n",
        "# Entrenamos el perceptrón multicapa\n",
        "\n",
        "# Learning curves\n",
        "visualize_learning_curve(...)\n",
        "\n",
        "# Evaluando el modelo de predicción con las imágenes de test\n",
        "evaluate_model(...)\n",
        "\n",
        "# Almaceno el modelo en Drive"
      ],
      "metadata": {
        "id": "GeqQ4ffG50lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSb1uTpJn_eC"
      },
      "source": [
        "## **REDUCIENDO OVERFITTING MEDIANTE DATA AUGMENTATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSXhGQa3PQKc"
      },
      "source": [
        "#### **- Acondicionando dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zUYUzxuFOg9"
      },
      "source": [
        "# Binarizar etiquetas - por si es necesario convertir a one-hot encoding\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEgHlw7oPSl6"
      },
      "source": [
        "#### **- Creando un contenedor DataGenerator para el aumento automático de muestras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA0swBO3NHlQ"
      },
      "source": [
        "# Crear Image DataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jiAe2cEPk0Y"
      },
      "source": [
        "#### **- Inspeccionando las muestras generadas sintéticamente**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtgZCInwNHlX"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "sample = 45\n",
        "plt.imshow(image.array_to_img(trainX[sample]))\n",
        "plt.show()\n",
        "print('Label = {}'.format(labelNames[trainY[sample].argmax(axis=0)]))\n",
        "\n",
        "fig, axes = plt.subplots(2,2)\n",
        "i = 0\n",
        "for batch in datagen.flow(trainX[sample].reshape((1,32,32,3)),batch_size=1):\n",
        "    #plt.figure(i)\n",
        "    axes[i//2,i%2].imshow(image.array_to_img(batch[0]))\n",
        "    i += 1\n",
        "    if i == 4:\n",
        "        break\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RCjtfY8Ps-G"
      },
      "source": [
        "#### **- Creando la topología de red neuronal y entrenándola: CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgy3NVSx8y7x"
      },
      "source": [
        "# Arquitectura de red - modo API Functional\n",
        "\n",
        "# 1.BASE MODEL\n",
        "\n",
        "# 2.TOP MODEL\n",
        "\n",
        "# 3. Unimos las entradas y salidas del modelo\n",
        "\n",
        "# Compilamos el modelo y entrenamos\n",
        "\n",
        "# Entrenamos el perceptrón multicapa\n",
        "\n",
        "# Learning curves\n",
        "visualize_learning_curve(...)\n",
        "\n",
        "# Evaluando el modelo de predicción con las imágenes de test\n",
        "evaluate_model(...)\n",
        "\n",
        "# Almaceno el modelo en Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vddlOmKhmIMy"
      },
      "source": [
        "**EJERCICIO PROPUESTO:** Modificar la ejecución con Data Augmentation para que sea directamente comparable a la ejecución por defecto. Para ello, el validation data debe ser correcto. Pista: Llevar a cabo el validation split cuando se instancia el objeto ImageDataGenerator. El método flow también se verá afectado (leer documentación)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bKNJiApNHlj"
      },
      "source": [
        "## **TRABAJANDO CON REDES PRE-ENTRENADAS: TRANSFER LEARNING & FINE-TUNING**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n64pEFv_YGu_"
      },
      "source": [
        "#### **- Cargando el conjunto de datos y acondicionándolo como en la VGG**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov7MLBjsVWjE"
      },
      "source": [
        "# Imports necesarios\n",
        "\n",
        "# Importando y normalizando el set de datos CIFAR10\n",
        "\n",
        "# One-hot encoding\n",
        "\n",
        "# IMPORTANTE: Se normalizan los datos como se normalizaron en el entrenamiento con ImageNet!!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LB0W9DWJYLQo"
      },
      "source": [
        "#### **- Cargando la topología de CNN (base model)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRfr9ZWeNHlm"
      },
      "source": [
        "# keras incluye varias arquitecturas\n",
        "# VGG16, VGG19, ResNet50, Xception, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet, RasNet\n",
        "# documentacion https://keras.io/applications/\n",
        "# Visual Geometry Group 16 / 19 (numero de layers)\n",
        "# 1 y 2 en la competicion ImageNet 2014\n",
        "# Kernels pequeños de 3x3\n",
        "\n",
        "# Cargar arquitectura y pesos\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgp6wGnDYSTs"
      },
      "source": [
        "#### **- Creando el top model y congelando TODAS las capas convolucionales (TRANSFER LEARNING)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTvDJDz2NHlq"
      },
      "source": [
        "# Conectar el modelo con el top model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaZxEUW3YYGI"
      },
      "source": [
        "#### **- Entrenando la solución**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0h_rPl2RpBz"
      },
      "source": [
        "# Import the necessary packages\n",
        "\n",
        "# Compilamos el modelo y entrenamos\n",
        "\n",
        "# Entrenamos el perceptrón multicapa\n",
        "\n",
        "# Learning curves\n",
        "visualize_learning_curve(...)\n",
        "\n",
        "# Evaluando el modelo de predicción con las imágenes de test\n",
        "evaluate_model(...)\n",
        "\n",
        "# Almaceno el modelo en Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDXy7tDNYpeL"
      },
      "source": [
        "#### **- Creando el top model y descongelando bloques convolucionales (FINE TUNING)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzM0C_C9mWAy"
      },
      "source": [
        "# Imports que vamos a necesitar\n",
        "\n",
        "# Cargamos el dataset CIFAR10\n",
        "\n",
        "# Normalizamos las entradas de idéntica forma a como lo hicieron para entrenar la VGG16 en imageNet\n",
        "\n",
        "# Definimos dimensiones de nuestros datos de entrada y lista con las categorias de las clases\n",
        "\n",
        "# En caso de inestabilidades numéricas pasar datos a one-hot encoding\n",
        "\n",
        "# Importamos VGG16 con pesos de imagenet y sin top_model especificando tamaño de entrada de datos\n",
        "\n",
        "# Mostramos la arquitectura\n",
        "\n",
        "# Congelamos las capas de los 4 primeros bloques convolucionales, el quinto se re-entrena\n",
        "# En base_model.layers.name tenemos la información del nombre de la capa\n",
        "\n",
        "# Cogemos la última capa del model y le añadimos nuestro clasificador (top_model)\n",
        "\n",
        "# Compilamos el modelo y entrenamos\n",
        "\n",
        "# Entrenamos el perceptrón multicapa\n",
        "\n",
        "# Learning curves\n",
        "visualize_learning_curve(...)\n",
        "\n",
        "# Evaluando el modelo de predicción con las imágenes de test\n",
        "evaluate_model(...)\n",
        "\n",
        "# Almaceno el modelo en Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcZmIBgRwc_Y"
      },
      "source": [
        "**EJERCICIO PROPUESTO:** Combinar fine tuning con la técnica de data augmentation para reducir overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk8Q9thGve4T"
      },
      "source": [
        "## **VISUALIZANDO POR DENTRO UNA CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjtSqb4vo1p"
      },
      "source": [
        "#### **- Visualizar activaciones intermedias**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueFTOHu5xRP1"
      },
      "source": [
        "- Visualizar el output de las capas de la red\n",
        "- 2D imagen por canal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NXrbEYOhgqJ"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Importando y normalizando el set de datos CIFAR10\n",
        "print(\"[INFO]: Loading CIFAR-10 data...\")\n",
        "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
        "labelNames = [\"Avión\", \"Automóvil\", \"Pájaro\", \"Gato\", \"Ciervo\", \"Perro\", \"Rana\", \"Caballo\", \"Barco\", \"Camión\"]\n",
        "\n",
        "#One-hot encoding\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW1zc38GNHl_"
      },
      "source": [
        "from keras.models import load_model\n",
        "model_augmentation = load_model(BASE_FOLDER+'resources/convnet_augmentation.h5')\n",
        "model_augmentation.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piy9J5ODNHmJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "%matplotlib inline\n",
        "\n",
        "# Visualizando imagen\n",
        "sample = 1000\n",
        "input_img = trainX[sample].reshape((1,32,32,3))\n",
        "plt.imshow(array_to_img(trainX[sample]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modificar el modelo para que nos devuelva los mapas de activación\n"
      ],
      "metadata": {
        "id": "vSAtA0-p2a0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVP3qmz5NHmN"
      },
      "source": [
        "# Visualización de la salida de un filtro - activacion, 32 canales, feature map de 30x30\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTtUICHbNHmU"
      },
      "source": [
        "# Visualización de las activaciones en todas las capas\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJp-qx1cNHmg"
      },
      "source": [
        "### Interpretacion\n",
        "- Capas iniciales son como detectores de bordes\n",
        "- Capas más profundas son más difíciles de interpretar (abstractas) y tienen información relativa a la clase de imagen\n",
        "- La activación de capas profundas es más dispersa (sparse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpe6aM9bvyyc"
      },
      "source": [
        "#### **- Visualizar filtros convolucionales**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnVLRy4-NHmg"
      },
      "source": [
        "- Visualizar las imagenes que maximizan la respuesta a un filtro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bpWxzCTNHmg"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "from keras import backend as K\n",
        "\n",
        "model = VGG16(weights='imagenet',include_top=False)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vklaIPySNHmi"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def gen_max_response_pattern(layer_name, filter_index, size=32):\n",
        "    layer_output = model.get_layer(layer_name).output\n",
        "    loss = K.mean(layer_output[:,:,:,filter_index])\n",
        "\n",
        "    # Para obtener el patron que responde de forma máxima, utilizamos descenso del gradiente\n",
        "    grads = K.gradients(loss,model.input)[0] # Seleccionar el primero, ya que esto devuelve una lista\n",
        "    # Normalización para ayudar al proceso del gradiente\n",
        "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5) # Última constante para evitar dividir por 0\n",
        "    # Definir funcion que calcula la pérdida y el gradiente de la imagen\n",
        "    iterate = K.function([model.input], [loss,grads])\n",
        "    loss_value, grads_value = iterate([np.zeros((1,size,size,3))])\n",
        "\n",
        "    # Iniciamos con imagen aleatoria\n",
        "    input_img_data = np.random.random((1,size,size,3)) * 20 + 128\n",
        "\n",
        "    step = 1. # Magnitud de cada actualizacion en el gradiente\n",
        "    n_steps = 40 # Número de iteraciones\n",
        "    for i in range(n_steps):\n",
        "        loss_value, grads_value = iterate([input_img_data])\n",
        "        input_img_data += grads_value * step\n",
        "    img = input_img_data[0]\n",
        "    # Procesar la imagen resultante\n",
        "    img -= img.mean()\n",
        "    img /= img.std() + 1e-5\n",
        "    img *= 0.1\n",
        "    img += 0.5\n",
        "    img = np.clip(img,0,1)\n",
        "    img *= 255\n",
        "    img = np.clip(img,0,255).astype('uint8')\n",
        "\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7dPR_XDNHmt"
      },
      "source": [
        "# mostrar un patron para un filtro\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "layer_name = 'block2_conv1'\n",
        "filter_index = 112 # canal a estudiar\n",
        "\n",
        "img = gen_max_response_pattern(layer_name,filter_index,32)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBdd-qvdNHmv"
      },
      "source": [
        "**EJERCICIO PROPUESTO:** Mostrar los patrones de maxima activacion para todos los filtros de una capa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0nNoWlXv5J7"
      },
      "source": [
        "#### **- Visualizar hetmaps de activación por clase**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psj1EvKvNHmw"
      },
      "source": [
        "- Útil para averiguar qué partes de la imagen contribuyen más a la decisión\n",
        "- Interesante para saber qué pasa cuando se cometen errores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd_PfCGmNHmx"
      },
      "source": [
        "# Técnica utiliza gradientes Ramprasaath, R. Selvaraju et al. (2017). https://arxiv.org/abs/1610.02391\n",
        "from keras.applications import VGG16\n",
        "\n",
        "model = VGG16(weights='imagenet',include_top=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reuCIeynNHmy"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "# Cargar imagen de gato\n",
        "img = image.load_img(BASE_FOLDER+'resources/cat.jpg', target_size=(224,224))\n",
        "x = image.img_to_array(img) # a array de (224,224,3)\n",
        "x = np.expand_dims(x, axis=0) # a array de (1,224,224,3)\n",
        "x = preprocess_input(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2eePG0wNHmz"
      },
      "source": [
        "# Testeando el output\n",
        "prediction = model.predict(x)\n",
        "print(decode_predictions(prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukvcCRaLNHm1"
      },
      "source": [
        "tabby_output_index = np.argmax(prediction[0])\n",
        "tabby_output = model.output[:,tabby_output_index]\n",
        "last_conv_layer = model.get_layer('block5_conv3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXwixXFKNHnJ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras import backend as K\n",
        "\n",
        "grads = K.gradients(tabby_output, last_conv_layer.output)[0]\n",
        "pooled_grads = K.mean(grads, axis=(0,1,2))\n",
        "iterate = K.function( [model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "\n",
        "# Multiplicar cada canal en el feature map por como de importante el canal es con respecto a la clase \"tabby\"\n",
        "for i in range(512):\n",
        "    conv_layer_output_value[:,:,i] *= pooled_grads_value[i]\n",
        "\n",
        "heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
        "\n",
        "# Visualizar\n",
        "heatmap = np.maximum(heatmap,0)\n",
        "heatmap /= np.max(heatmap)\n",
        "fig,axes = plt.subplots(1,2)\n",
        "axes[0].matshow(heatmap)\n",
        "axes[1].imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjwW0XUHNHnM"
      },
      "source": [
        "**EJERCICIO PROPUESTO:** Obtener el heatmap para las otras clases en la lista de prediccion (Egyptian_cat, tiger_cat, etc.)."
      ]
    }
  ]
}